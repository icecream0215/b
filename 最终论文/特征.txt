老师我现在模型训练完了，原先那个设想太不科学了，我最后用的是（）这5个模态，做了一个不引入语言线索的抑郁症预测(一个是因为引入语言线索后语言模型的权重会变得极大，因为抑郁症患者的视频中很容易出现“抑郁”这两个字，语言的区分度太强导致别的模态看起来没什么用了；二是因为不用语言就可以使用各种语言环境下的视频做训练，训练出的模型也可以直接适用于各个语言环境，我找不到中文的抑郁症分类数据集)，然后训练出的模型十折交叉验证的acc大概是75%；我写完了论文的绪论和文献综述，然后我现在是要做消融实验还是先把程序做出来（就是做设计的话论文和程序哪个更重要一点）
我的绪论，文献综述，数据处理，模型架构，优越性写完了

音频npy：128维度，采用预训练的VGGish【41】
视频npy：
frame
face_id
timestamp
confidence
success
gaze_0_x：vlog的视线追踪
gaze_0_y
gaze_0_z
gaze_1_x
gaze_1_y
gaze_1_z
gaze_angle_x
gaze_angle_y
eye_lmk_x_0 ~ eye_lmk_x_55
eye_lmk_y_0 ~ eye_lmk_y_55
eye_lmk_X_0 ~ eye_lmk_X_55
eye_lmk_Y_0 ~ eye_lmk_Y_55
eye_lmk_Z_0 ~ eye_lmk_Z_55
pose_Tx
pose_Ty
pose_Tz
pose_Rx
pose_Ry
pose_Rz
x_0 ~ x_67:和vlog的LM相同
y_0 ~ y_67
AU01_r~AU45_r：共17
AU01_c~AU45_c：共18

注(此处在论文中应附上参考文献)：
FAU：AU0-45强度，AU0-45是否激活（实际上只用了分类）
面部标志：0-67，共68个关键点的x,y坐标
凝视：
眼部关键点：
头部姿势特征：头部位置(xyz)旋转方向(xyz)

特征并没有全用上，所以我特征提取的csv没必要一样，只要改一下tcnfeaturn的行数就行了
对于au:我不知道为什么要交换，不知道为什么选17个而不是18个：
1.17个0/1AU特征
2.17个连续值AU特征 ♥(用的就是自适应平均池化)
3.18个0/1AU特征
4.”1“+280维的三模态+深度可分离卷积 难
5.二模态+深度可分离卷积+修改批次大小和学习率：巨差
6.使用多层感知机
7.先注意两个，再对这两个做transformer
8.17+1

